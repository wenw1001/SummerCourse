{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引用需要的函式庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定義資料集\n",
    "讀取CSV檔中的MNIST資料集，每一列代表一個圖片的類別與784個畫素值  \n",
    "將784個畫素重新排列為28*28的二維陣列，並轉換為Pillow image便於後續的資料前處理  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file) # read data from csv file as a pandas dataframe\n",
    "        self.transform = transform # initial transfrom\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # transfer data from list to Pillow image\n",
    "        image = Image.fromarray(self.data_frame.iloc[idx, 1:].values.reshape(28, 28).astype(np.uint8))\n",
    "        \n",
    "        label = int(self.data_frame.iloc[idx, 0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料前處理\n",
    "定義適用於訓練集與測試集的transform分別進行各自的資料前處理流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.5, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4850, 0.4560, 0.4060], std=[0.2290, 0.2240, 0.2250])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4850, 0.4560, 0.4060], std=[0.2290, 0.2240, 0.2250])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立訓練集、驗證集、測試集\n",
    "由於MNIST資料集未提供獨立的驗證集，因此將一半的測試集拆分出來做為驗證集  \n",
    "驗證集可以監控模型是否overfitting，同時作為保存最佳模型的標準"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'mnist/mnist_train.csv'\n",
    "test_path = 'mnist/mnist_test.csv'\n",
    "\n",
    "train_data = MNISTDataset(csv_file=train_path, transform=train_transform)\n",
    "test_data = MNISTDataset(csv_file=test_path, transform=test_transform)\n",
    "testLen = int(len(test_data) * 0.5)\n",
    "valLen = len(test_data) - testLen\n",
    "test_data, val_data = random_split(test_data, [testLen, valLen])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立DataLoader\n",
    "可決定batch size、以及資料集載入時是否打亂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練用硬體\n",
    "決定使用GPU或是CPU進行訓練  \n",
    "範例優先選用GPU，若GPU不可用則使用CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 選擇Model、Loss Function以及Optimizer\n",
    "修改最後的全連階層使其適應資料集的類別數量  \n",
    "設定完成後會將model移至GPU/CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\summercourse\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\summercourse\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), weight_decay=0.001, lr=0.0001)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練過程\n",
    "範例訓練過程會歷遍資料集共20輪  \n",
    "每一輪都會計算training與validation的loss與accuracy  \n",
    "以validation accuracy為標準保存最佳的模型參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 1.0478, Training Accuracy: 0.6540\n",
      "Validation Loss: 0.5730, Validation Accuracy: 0.8206\n",
      "Epoch 2/20, Training Loss: 0.4921, Training Accuracy: 0.8426\n",
      "Validation Loss: 0.4942, Validation Accuracy: 0.8380\n",
      "Epoch 3/20, Training Loss: 0.3884, Training Accuracy: 0.8730\n",
      "Validation Loss: 0.3654, Validation Accuracy: 0.8774\n",
      "Epoch 4/20, Training Loss: 0.3391, Training Accuracy: 0.8887\n",
      "Validation Loss: 0.3044, Validation Accuracy: 0.8984\n",
      "Epoch 5/20, Training Loss: 0.3170, Training Accuracy: 0.8965\n",
      "Validation Loss: 0.2890, Validation Accuracy: 0.9068\n",
      "Epoch 6/20, Training Loss: 0.2953, Training Accuracy: 0.9033\n",
      "Validation Loss: 0.3008, Validation Accuracy: 0.8980\n",
      "Epoch 7/20, Training Loss: 0.2735, Training Accuracy: 0.9096\n",
      "Validation Loss: 0.2206, Validation Accuracy: 0.9256\n",
      "Epoch 8/20, Training Loss: 0.2567, Training Accuracy: 0.9140\n",
      "Validation Loss: 0.1914, Validation Accuracy: 0.9426\n",
      "Epoch 9/20, Training Loss: 0.2499, Training Accuracy: 0.9165\n",
      "Validation Loss: 0.2146, Validation Accuracy: 0.9302\n",
      "Epoch 10/20, Training Loss: 0.2379, Training Accuracy: 0.9216\n",
      "Validation Loss: 0.1540, Validation Accuracy: 0.9480\n",
      "Epoch 11/20, Training Loss: 0.2317, Training Accuracy: 0.9229\n",
      "Validation Loss: 0.2166, Validation Accuracy: 0.9288\n",
      "Epoch 12/20, Training Loss: 0.2213, Training Accuracy: 0.9264\n",
      "Validation Loss: 0.2166, Validation Accuracy: 0.9324\n",
      "Epoch 13/20, Training Loss: 0.2203, Training Accuracy: 0.9275\n",
      "Validation Loss: 0.1799, Validation Accuracy: 0.9384\n",
      "Epoch 14/20, Training Loss: 0.2128, Training Accuracy: 0.9291\n",
      "Validation Loss: 0.2109, Validation Accuracy: 0.9240\n",
      "Epoch 15/20, Training Loss: 0.2058, Training Accuracy: 0.9303\n",
      "Validation Loss: 0.1976, Validation Accuracy: 0.9338\n",
      "Epoch 16/20, Training Loss: 0.2027, Training Accuracy: 0.9323\n",
      "Validation Loss: 0.1577, Validation Accuracy: 0.9436\n",
      "Epoch 17/20, Training Loss: 0.1940, Training Accuracy: 0.9363\n",
      "Validation Loss: 0.1969, Validation Accuracy: 0.9362\n",
      "Epoch 18/20, Training Loss: 0.1949, Training Accuracy: 0.9344\n",
      "Validation Loss: 0.1870, Validation Accuracy: 0.9352\n",
      "Epoch 19/20, Training Loss: 0.1886, Training Accuracy: 0.9373\n",
      "Validation Loss: 0.2774, Validation Accuracy: 0.9060\n",
      "Epoch 20/20, Training Loss: 0.1866, Training Accuracy: 0.9380\n",
      "Validation Loss: 0.1720, Validation Accuracy: 0.9404\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            # Save model weights\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            best_accuracy = val_accuracy\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試模型\n",
    "載入最佳的模型參數  \n",
    "在testing set測試模型並計算loss與accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mingyiao\\AppData\\Local\\Temp\\ipykernel_32292\\2173399408.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss: 0.1535, Testing Accuracy: 0.9490\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "model.eval()  # 设置模型为评估模式\n",
    "running_test_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_test_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss = running_test_loss / len(test_loader.dataset)\n",
    "test_accuracy = correct_test / total_test\n",
    "\n",
    "print(f'Testing Loss: {test_loss:.4f}, Testing Accuracy: {test_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summercourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
